{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f47eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add Azure OpenAI package\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "def openai_test_4(): \n",
    "        \n",
    "    try: \n",
    "    \n",
    "        # Get configuration settings \n",
    "        load_dotenv()\n",
    "        azure_oai_endpoint = os.getenv(\"AZURE_OAI_ENDPOINT\")\n",
    "        azure_oai_key = os.getenv(\"AZURE_OAI_KEY\")\n",
    "        azure_oai_deployment = os.getenv(\"AZURE_OAI_DEPLOYMENT\")\n",
    "        \n",
    "        # Initialize the Azure OpenAI client...\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=azure_oai_endpoint,\n",
    "            api_key=azure_oai_key,\n",
    "            api_version=\"2025-01-01-preview\",\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\" : \"system\",\n",
    "                \"content\" : [\n",
    "                {\n",
    "                    \"type\" : \"text\",\n",
    "                    \"text\" : \"너는 이미지에 대한 설명을 해주는 역할이야\"\n",
    "                }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        IMAGE_PATH = \"C:/workspace/mslearn-openai/Labfiles/personal-exer/images/squirrel.webp\"\n",
    "        encoded_image = base64.b64encode(open(IMAGE_PATH, 'rb').read()).decode('ascii')\n",
    "\n",
    "        while True:\n",
    "            # Get input text\n",
    "            input_text = input(\"질문을 입력하세요 ('quit' 이라고 입력하면 종료): \")\n",
    "            if input_text.lower() == \"quit\":\n",
    "                break\n",
    "            if len(input_text) == 0:\n",
    "                print(\"질문을 다시 작성해주세요.\")\n",
    "                continue\n",
    "\n",
    "            print(\"질문 : \" + input_text)\n",
    "\n",
    "            # print(\"\\n답변하는중...\\n\\n\"\n",
    "            \n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\" : \"user\",\n",
    "                    \"content\" : [\n",
    "                    {\n",
    "                        \"type\" : \"text\",\n",
    "                        \"text\" : input_text\n",
    "\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\" : \"image_url\",\n",
    "                        \"image_url\" : {\n",
    "                            \"url\" : f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # 나는 한 입력-출력 당 user 와 assistant를 둘 다 추가하니 이전 3개까지 기억하기 위해 system값 포함 8개를 기억함\n",
    "            # 시스템(1개) + 현재 나의 입력(1개) + 이전 3개의 입력-출력 쌍(6개) = 8개\n",
    "            if len(messages) > 8 :\n",
    "                messages = [messages[0]] + messages[-7:]\n",
    "            \n",
    "            # Add code to send request...\n",
    "            completion = client.chat.completions.create(\n",
    "                model=azure_oai_deployment,\n",
    "                messages=messages,\n",
    "                max_tokens=300,\n",
    "                temperature=0.7,\n",
    "                top_p=0.95,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0,\n",
    "                stop=None,\n",
    "                stream=False\n",
    "            )\n",
    "            \n",
    "            print(\"답변 : \" + completion.choices[0].message.content + \"\\n\")\n",
    "\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\" : \"assistant\",\n",
    "                    \"content\" : [\n",
    "                    {\n",
    "                        \"type\" : \"text\",\n",
    "                        \"text\" : completion.choices[0].message.content\n",
    "\n",
    "                    }\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "            \n",
    "\n",
    "    except Exception as ex:\n",
    "        print(ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3229a181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 : 이 이미지에 대해서 설명해줘!\n",
      "답변 : 이 이미지는 다소 귀엽고 재미있는 표정을 짓고 있는 다람쥐의 모습입니다. 다람쥐는 한쪽 앞다리를 앞으로 뻗고 있으며, 입을 벌리고 있는 모습은 마치 놀라거나 말하고 있는 듯한 인상을 줍니다. 털은 갈색과 회색이 섞여 있으며, 배 부분은 하얀색으로 보입니다. 배경은 흐릿하게 처리되어 있어 다람쥐가 더 돋보이게 되어 있습니다. 이 장면은 다람쥐의 특유의 호기심과 발랄함을 잘 나타내고 있습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "openai_test_4()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
